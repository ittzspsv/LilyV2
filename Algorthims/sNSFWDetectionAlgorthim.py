import json
import unicodedata
import re
from rapidfuzz import process

SUSPICIOUS_SYMBOLS = {'@', 'â‚¬', '$', '%', '&', '!', 'Â¥', 'Â¢', 'Â¤'}

leet_dict = {
    '0': 'o', '1': 'i', '3': 'e', '4': 'a', '5': 's', '7': 't',
    '@': 'a', 'â‚¬': 'e', '$': 's', '!': 'i', 'Â£': 'l', '8': 'b'
}

homoglyph_map = {
    'ğ€': 'A', 'ğ–†': 'a', 'ğµ': 'B', 'ğ‘': 'b', 'ğ’': 'C', 'ğ’¸': 'c',
    'ğ’Ÿ': 'D', 'ğ’¹': 'd', 'ğ¸': 'E', 'ğ‘’': 'e', 'ğ‘­': 'F', 'ğ‘“': 'f',
    'ğ‘®': 'G', 'ğ‘”': 'g', 'ğ‘¯': 'H', 'ğ’½': 'h', 'ğ¼': 'I', 'ğ‘–': 'i',
    'ğ’¥': 'J', 'ğ’¿': 'j', 'ğ¾': 'K', 'ğ‘˜': 'k', 'ğ’§': 'L', 'ğ“': 'l',
    'ğ‘€': 'M', 'ğ‘š': 'm', 'ğ’©': 'N', 'ğ“ƒ': 'n', 'ğ‘¶': 'O', 'ğ‘œ': 'o',
    'ğ’«': 'P', 'ğ“…': 'p', 'ğ’¬': 'Q', 'ğ“†': 'q', 'ğ‘…': 'R', 'ğ“‡': 'r',
    'ğ’®': 'S', 'ğ“ˆ': 's', 'ğ‘‡': 'T', 'ğ“‰': 't', 'ğ‘¼': 'U', 'ğ“Š': 'u',
    'ğ’±': 'V', 'ğ“‹': 'v', 'ğ‘¾': 'W', 'ğ“Œ': 'w', 'ğ’³': 'X', 'ğ“': 'x',
    'ğ’´': 'Y', 'ğ“': 'y', 'ğ’µ': 'Z', 'ğ“': 'z'
}
ZERO_WIDTH_CHARS = re.compile(r'[\u200B-\u200F\u202A-\u202E\u2060-\u206F]')


def regional_indicator_to_text(text):
    styled_letters = {
        "ğŸ…°ï¸": "A", "ğŸ…±ï¸": "B", "ğŸ†": "AB", "ğŸ†‘": "CL", "ğŸ†’": "COOL",
        "ğŸ†“": "FREE", "ğŸ†”": "ID", "ğŸ†•": "NEW", "ğŸ†–": "NG", "ğŸ†—": "OK",
        "ğŸ†˜": "SOS", "ğŸ†™": "UP", "ğŸ†š": "VS", "â“‚ï¸": "M", "ğŸ…¾ï¸": "O"
    }
    
    def convert_match(match):
        char = match.group(0)
        char = char.replace("ï¸", "") 
        if char in styled_letters:
            return styled_letters[char]
        if '\U0001F1E6' <= char <= '\U0001F1FF':
            unicode_val = ord(char) - 0x1F1E6
            return chr(unicode_val + ord('A'))
        if '\u24B6' <= char <= '\u24CF':
            return chr(ord(char) - 0x24B6 + ord('A'))
        return char
    
    text = text.replace("ï¸", "")
    converted_text = re.sub(r'[\U0001F1E6-\U0001F1FFâ’¶-â“\U0001F170-\U0001F189]', convert_match, text)
    return converted_text.replace(" ", "")

def normalize_text(text):
    text = ZERO_WIDTH_CHARS.sub('', text)
    text = unicodedata.normalize('NFKC', text)
    text = ''.join(homoglyph_map.get(char, char) for char in text)
    text = ''.join(leet_dict.get(char, char) for char in text)
    text = re.sub(r'[^a-zA-Z0-9\s/()]+', '', text)
    text = re.sub(r'(?<=\b[a-zA-Z]) (?=[a-zA-Z]\b)', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    text = text.lower()
    return text



def load_nsfw_words(file_path):
    with open(file_path, "r", encoding="utf-8") as file:
        nsfw_words = json.load(file)
    return set(nsfw_words)

def is_nsfw(text, nsfw_set, threshold=96):
    words = re.findall(r"\b\w+\b", text.lower())
    words = [normalize_text(sword) for sword in words]
    
    return any(process.extractOne(word, nsfw_set)[1] >= threshold for word in words)


nsfw_set = load_nsfw_words("nsfw.json")